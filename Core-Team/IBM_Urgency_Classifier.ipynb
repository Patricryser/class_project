{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IBM - Urgency Classifier (SVC)",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWZfespIZ5_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import relevant packages\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjaCceEggfXa",
        "colab_type": "code",
        "outputId": "a4a93530-e11e-4355-ea50-dff1d06c0d38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Retrieve csv from drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4gUMWVAqllj",
        "colab_type": "code",
        "outputId": "ccc097be-7069-496a-87f5-bf959ed44fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Store dataset in pandas dataframe\n",
        "\n",
        "master_df = pd.read_csv('/content/drive/My Drive/Consumer_Complaints.csv')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (5,6,11,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBkgxRNGaRd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Only keep rows with complaint narratives\n",
        "\n",
        "proc_df = master_df.dropna(subset=['Consumer complaint narrative'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPwDlJnMawyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Take sample of even amounts of timely and un-timely responses\n",
        "\n",
        "new_df = proc_df[proc_df['Timely response?']=='Yes'].sample(5000)\n",
        "\n",
        "new_df2 = proc_df[proc_df['Timely response?']=='No'].sample(5000)\n",
        "\n",
        "df = new_df.append(new_df2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52cXhIvQa2Gv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean the data with regex, so that there are no numbers, special characters, or Xs\n",
        "\n",
        "clean = [re.sub('[^A-WY-Za-z]', ' ', nar) for nar in df['Consumer complaint narrative']]\n",
        "\n",
        "df['Cleaned narratives'] = [nar for nar in clean]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B6orvI2w4BH",
        "colab_type": "code",
        "outputId": "f2937b3a-08f0-44fb-db92-dd4d76eacd15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "split_nars = [nar.split() for nar in df['Cleaned narratives']] # split up words in narratives\n",
        "\n",
        "lem_nars = [[lemmatizer.lemmatize(word) for word in nar] for nar in split_nars] # lemmatize each word in each narrative\n",
        "\n",
        "df['Cleaned narratives'] = [' '.join(nar) for nar in lem_nars] # adjoin list of words by spaces for each narrative"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyxXBm7z9rUp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrpBerOdbEo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data into train and test data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Cleaned narratives'], \n",
        "                                                       df['Timely response?'], random_state=30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkrvaHaNb2Xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import relevant packages, such as TfidfVectorizer, StratifiedKFold, etc. And then vectorize the text with Tfidf.\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,3), min_df=3)\n",
        "\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "\n",
        "X_test = vectorizer.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz3Z_7vxRZEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define an f1 scorer to score the results\n",
        "\n",
        "def f1_scorer(tp, fp, fn):\n",
        "\n",
        "  precision = tp / (tp + fp)\n",
        "  recall = tp / (tp + fn)\n",
        "\n",
        "  f1 = (2 * precision * recall) / (precision + recall)\n",
        "\n",
        "  return f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPUgj_VHjlFg",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usH5vmoNb5da",
        "colab_type": "code",
        "outputId": "72937cdd-0da3-4e2a-c890-5112a2447589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc = SVC(kernel='linear')\n",
        "\n",
        "param_grid = {'C': [0.45, 0.5, 0.55, 0.6]}\n",
        "\n",
        "cv_input = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "\n",
        "grid = GridSearchCV(svc, param_grid, cv=cv_input).fit(X_train, y_train)\n",
        "\n",
        "print(f'Best param: {grid.best_params_}')\n",
        "\n",
        "print(f'Train score: {grid.score(X_train, y_train)}')\n",
        "\n",
        "print(f'Test score: {grid.score(X_test, y_test)}')\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, grid.predict(X_test)).ravel()\n",
        "\n",
        "print(f'The F1 score is: {f1_scorer(tp, fp, fn)}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best param: {'C': 0.6}\n",
            "Train score: 0.8713333333333333\n",
            "Test score: 0.7004\n",
            "The F1 score is: 0.6944104447164422\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}